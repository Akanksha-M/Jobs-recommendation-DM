{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Job Recommendation System.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbVSy6UT7xcA",
        "colab_type": "text"
      },
      "source": [
        "# Job Recommendation System"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNpsZWKs7xcB",
        "colab_type": "text"
      },
      "source": [
        "## What is a recommendation system?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgyCOAZ67xcC",
        "colab_type": "text"
      },
      "source": [
        "In a very general way, recommender systems are algorithms aimed at suggesting relevant items to users. \n",
        "\n",
        "A job recommendation system is essentially one that finds a suitable job for the applicant, based on the data input in chosen categories (city, domain, salary, etc.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgaA0jEG7xcC",
        "colab_type": "text"
      },
      "source": [
        "#### Types of Recommendation systems: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkAKW6pu7xcD",
        "colab_type": "text"
      },
      "source": [
        "- Collaborative Filtering \n",
        "- Content-Based Filtering \n",
        "- Hybrid Recommendation Systems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuUehNad7xcD",
        "colab_type": "text"
      },
      "source": [
        "## Content Based Recommenders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9vLHOSt7xcE",
        "colab_type": "text"
      },
      "source": [
        "Content-based filtering methods are based on a description of the item and a profile of the user’s preference.The recommendations are primarily based on the keywords provided by the user or those picked up by the system (based of previous selections). The 'best-matched' items are recommended. <br>\n",
        "<br>\n",
        "This system is put to use where there isn't much information about the user prior to the search. For this reason, they are also called item-item interactions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3iFwvRu7xcE",
        "colab_type": "text"
      },
      "source": [
        "Example: At Pandora, a team of musicians labeled each music with more than 400 attributes. Then, when a user selects a music station, songs that match the station’s attributes will be added to the playlist.\n",
        "For Pandora, manual efforts/costs are needed to create music attributes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGku_1sI7xcF",
        "colab_type": "text"
      },
      "source": [
        "##### Similarity Between Content\n",
        "\n",
        "Text A: London Paris London\n",
        "\n",
        "Text B: Paris Paris London\n",
        "\n",
        "Finding similarity between the text.\n",
        "\n",
        "<img src=\"http://www.codeheroku.com/static/blog/images/pid14_find_cos_theta.png\" align=\"left\" style=\"width:500px; height:300px\">\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "748ILKaV7xcF",
        "colab_type": "text"
      },
      "source": [
        "### Code for Cosine Distance Rule"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osGOClMJ7xcG",
        "colab_type": "text"
      },
      "source": [
        "Sample question stored in 'text'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWt6X-5G7xcG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = [\"London Paris London\", \"Paris Paris London\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfsFIvsg7xcJ",
        "colab_type": "text"
      },
      "source": [
        "CountVectorizer- Convert a collection of text documents to a matrix of token counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqhK7jRX7xcK",
        "colab_type": "text"
      },
      "source": [
        "Using 'CountVectorizer' to count word frequency in a corpus.\n",
        "\n",
        "Matrix:\n",
        "\n",
        "[frequencies in first sentence]\n",
        "\n",
        "[frequencies in second sentence]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhDPa1Hi7xcL",
        "colab_type": "code",
        "colab": {},
        "outputId": "062823de-4c9c-4185-dbbe-ba5cb95f96a2"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer()\n",
        "count_matrix = cv.fit_transform(text)\n",
        "print(count_matrix.toarray())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2 1]\n",
            " [1 2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bkn9xDQ57xcP",
        "colab_type": "code",
        "colab": {},
        "outputId": "3ff52bd9-a729-4bc2-91e2-979e6e741f4f"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "similarity_scores = cosine_similarity(count_matrix)\n",
        "print(similarity_scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.  0.8]\n",
            " [0.8 1. ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVukmjut7xcR",
        "colab_type": "text"
      },
      "source": [
        "Interpreting this, says that Text A is similar to Text A(itself) by 100%(position [0,0]) and Text A is similar to Text B by 80%(position [0,1])."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9J9TwJW7xcS",
        "colab_type": "text"
      },
      "source": [
        "*Example:* The user wants to find a job with the requirements based on Title, Location and Company Name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tffN-rSs7xcS",
        "colab_type": "text"
      },
      "source": [
        "## Scrapping the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bk80oqc-7xcT",
        "colab_type": "text"
      },
      "source": [
        "We used real time jobs posted on Naukri.com for building this recommendation system. <br>\n",
        "\n",
        "*Note*: Dataset scrapped on 26th March 2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlwZ-Uh_7xcT",
        "colab_type": "text"
      },
      "source": [
        "### What we wanted to scrape?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PUlpSg77xcT",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://i.ibb.co/ZztsFbb/scraping2.png\" align=\"left\" style=\"width:800px; height:300px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMyKyWRv7xcU",
        "colab_type": "text"
      },
      "source": [
        "### Limiting our scraping scope to: <br>\n",
        "Data Scientist, SDE, App Developer and QA jobs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FU-6iTIt7xcV",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://i.ibb.co/808KJWr/scraping1.png\" align=\"left\" style=\"width:800px; height:300px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upliGlDj7xcV",
        "colab_type": "text"
      },
      "source": [
        "### Librariers required for building a Web Scrapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwhWsCzb7xcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from selenium import webdriver   # Used for Automated Scrapingon Chrome\n",
        "from bs4 import BeautifulSoup    # Python's HTML Parser\n",
        "from csv import DictWriter       # Python's DictWriter module\n",
        "from time import sleep           # Used to avoid banning of web scrapper on website"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzsjbMeX7xcY",
        "colab_type": "text"
      },
      "source": [
        "### Example of scraping one category "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzgSUiR57xcY",
        "colab_type": "text"
      },
      "source": [
        "The below code is used to find the 'Job Title' in the div block. <br>\n",
        "If found, the value is stored in title (try block).<br>\n",
        "Else the value of title is 'None' (except block)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoNLNP2c7xcZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    title = soup.find(\"a\", class_=\"title\").text.replace('\\n','')\n",
        "except:\n",
        "    title = 'None'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3mQJrDN7xcc",
        "colab_type": "text"
      },
      "source": [
        "Similarily, the other attributes such as location, company, salary etc are found.<br>\n",
        "Also two seperate categories called 'Trending' and 'Sponsored' are scrapped too. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHHBu_kg7xcd",
        "colab_type": "text"
      },
      "source": [
        "## Pre-Processing the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HS9qbioZ7xcd",
        "colab_type": "text"
      },
      "source": [
        "The dataset that we have used in our project was obtained by scrapping the naukri.com site for ceratin job titles. But, only certain features have been used from the data scrapped.\n",
        "<br>\n",
        "The required features are extracted from the DataFrame. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFlLiH5K7xce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import chain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCvGYMpa7xcg",
        "colab_type": "text"
      },
      "source": [
        "The itertools is a module in Python having a collection of functions that are used for handling iterators. They make iterating through the iterables like lists and strings very easily. One such itertools function is chain().\n",
        "<br>\n",
        "<br>\n",
        "The iternal working of chain can be implemented as given below :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qW8q-SbA7xcg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def chain(*iterables):\n",
        "     for it in iterables:\n",
        "       for each in it:\n",
        "           yield (each)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o-BZ3nbCmTN",
        "colab_type": "text"
      },
      "source": [
        "### Dataset before Pre-Processing:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EMwDcO9CUiI",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://i.ibb.co/s677ZPk/dataset.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UuH5r6Q7xci",
        "colab_type": "text"
      },
      "source": [
        "- We have made sure that the 'NaN' or 'none' values are replaced with 0 \n",
        "- The Missing values where, 'not disclosed', are filled with aggregates (eg: salary). This was possible as each job title's scrapped data is stored in a different file\n",
        "- We remove the text within the brackets along with the brackets.\n",
        "- For years of experience the data is in the format (ex: 3-5yrs) in which we consider only the minimum number of years that is required (here 3).\n",
        "- The repetetive itemsets are removed\n",
        "- If a single job is available in multiple cities/locations, they were stored as separate itemsets (multivalued attributes)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7jIyppu7xcj",
        "colab_type": "text"
      },
      "source": [
        "All of the above techniques have been applied to the dataset and can be observed in <b><em>https://github.com/dhruvshettty/job-recommender/blob/master/Data_Preprocessing/Preprocessing.py </b></em>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4N_AKxdN7xcj",
        "colab_type": "text"
      },
      "source": [
        "## Building the Recommendation Engine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yML95Wr17xck",
        "colab_type": "text"
      },
      "source": [
        "*Jobs.csv* contains all the scrapped jobs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41GAj8sR7xck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(\"Jobs.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpQlsfsu7xcm",
        "colab_type": "text"
      },
      "source": [
        "The preprocessed data is stored as a dataframe. The combineFeatures() method is applied to get the required features into a single column, as a string(as shown above). Post this, the dataset is cleaned to remove any blank values. \n",
        "<br>\n",
        "Following which,the countVectorizer() method is applied to get the similarity between the specified parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaNcyRVDD4th",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is done to consider the entire input as one entity\n",
        "# Space in between the different inputs is required for it to work\n",
        "def combine_features(row):\n",
        "    return row['title']+\" \"+row['location']+\" \"+row['experience_yrs']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeQIf0QZ7xcn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for feature in features:\n",
        "    df[feature] = df[feature].fillna('') #filling all NaNs with blank string\n",
        "df[\"combined_features\"] = df.apply(combine_features,axis=1)\n",
        "\n",
        "cv = CountVectorizer() \n",
        "count_matrix = cv.fit_transform(df[\"combined_features\"])\n",
        "\n",
        "cosine_sim = cosine_similarity(count_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FGTB7Ah7xcr",
        "colab_type": "text"
      },
      "source": [
        "The user may enter the values for the parameters selected above in order to get the similar results from the engine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8dPy6sz7xcs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "req_title = \"Data Scientist\"\n",
        "req_location = \"Bangalore\"\n",
        "req_experience = \"5\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7bFo08q7xcu",
        "colab_type": "text"
      },
      "source": [
        "Two functions will serve to be useful to index all the elements from combined_features, to be idexed wrt to each other also, to be i dentified wrt user requirements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSk91iCw7xcu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_job_from_index(Index):\n",
        "\treturn df[df.Index == Index][\"Company_Name\"].values[0],df[df.Index == Index][\"title\"].values[0],df[df.Index == Index][\"location\"].values[0],df[df.Index == Index][\"experience_yrs\"].values[0]\n",
        "    \n",
        "def get_index_from_job(Job_Title,Location,Job_Salary):\n",
        "\treturn df[df.title == title][\"Index\"].values[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGOVsI1Q7xcx",
        "colab_type": "text"
      },
      "source": [
        "We will access the row corresponding to this job in the similarity matrix. Thus, get the similarity scores of all other jobs wrt the user requirements, as above. \n",
        "<br>\n",
        "Then enumerate through all the similarity scores of that job, so attained, to make a tuple of job index and similarity score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gx-PjIGQ7xcx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "req_index = get_index_from_job(title,location,req_salary)\n",
        "\n",
        "similar_jobs = list(enumerate(cosine_sim[req_index])) \n",
        "\n",
        "sorted_similar_jobs = sorted(similar_jobs,key=lambda x:x[1],reverse=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YokHQsKj7xcz",
        "colab_type": "text"
      },
      "source": [
        "Finally, we will run a loop to print first 10 entries from sorted_similar_movieslist.\n",
        "These need to be identified based on indices in order to be sorted and displayed such that the most likely match apprears first and the rest follow in descending order of similarity.\n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNCIG4Zr7xc0",
        "colab_type": "text"
      },
      "source": [
        "So, after the output is generated we write the result into a csv file "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGwv_v9LFTTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i=0\n",
        "with open('Result.csv','w') as file:\n",
        "    csv_output = csv.writer(file)\n",
        "    csv_output.writerow(['company','title', 'city', 'exp'])\n",
        "    for job in sorted_jobs_available:    \n",
        "        data=get_job_from_index(job[0])\n",
        "        csv_output.writerow(data)\n",
        "        i=i+1\n",
        "        if i>10:\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPP-OLeuGWin",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://i.ibb.co/P4LZCwk/Screenshot-12.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKpTBQDVSYlR",
        "colab_type": "text"
      },
      "source": [
        "## Future:\n",
        "1) Add more user inputs like Salary, Skills etc <br>\n",
        "2) Remove entiries where years of experience criteria isn't met <br>"
      ]
    }
  ]
}